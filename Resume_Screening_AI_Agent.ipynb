{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtIX7n3SyVk_",
        "outputId": "f58d47d0-219c-4b71-8dba-36f93d9c7834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 1. Install & Import Libraries\n",
        "# ============================\n",
        "!pip install python-docx PyPDF2 nltk scikit-learn docx2txt\n",
        "\n",
        "import os\n",
        "import docx2txt\n",
        "import PyPDF2\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ============================\n",
        "# 2. Text Extraction Functions\n",
        "# ============================\n",
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    with open(path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(path):\n",
        "    return docx2txt.process(path)\n",
        "\n",
        "def extract_resume_text(path):\n",
        "    if path.endswith(\".pdf\"):\n",
        "        return extract_text_from_pdf(path)\n",
        "    elif path.endswith(\".docx\"):\n",
        "        return extract_text_from_docx(path)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# ============================\n",
        "# 3. Preprocessing Function\n",
        "# ============================\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # remove numbers\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
        "    text = text.strip()\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# ============================\n",
        "# 4. Experience Extraction Function (Improved)\n",
        "# ============================\n",
        "def extract_years_of_experience(text):\n",
        "    text = text.lower()\n",
        "    years = []\n",
        "\n",
        "    # Pattern 1: \"X years\", \"X+ years\", \"X yrs\", \"X+ yrs\", decimals too\n",
        "    pattern1 = r'(\\d+(?:\\.\\d+)?)\\s*\\+?\\s*(years?|yrs?)'\n",
        "\n",
        "    # Pattern 2: \"over X years\", \"more than X years\"\n",
        "    pattern2 = r'(?:over|more than)\\s+(\\d+(?:\\.\\d+)?)\\s*(years?|yrs?)'\n",
        "\n",
        "    # Pattern 3: \"2018 - 2022\", \"2017 to 2021\"\n",
        "    pattern3 = r'(\\d{4})\\s*[-to]+\\s*(\\d{4})'\n",
        "\n",
        "    # Pattern 4: \"Since 2015\", \"From 2016\"\n",
        "    pattern4 = r'(since|from)\\s+(\\d{4})'\n",
        "\n",
        "    # Pattern 5: \"experience of X years\"\n",
        "    pattern5 = r'experience\\s+of\\s+(\\d+(?:\\.\\d+)?)\\s*(years?|yrs?)'\n",
        "\n",
        "    # Pattern 6 (NEW): \"X months\", \"X+ months\", \"over X months\"\n",
        "    pattern6 = r'(\\d+(?:\\.\\d+)?)\\s*\\+?\\s*(months?|mnths?)'\n",
        "\n",
        "    # Current year for \"since/from\"\n",
        "    current_year = pd.Timestamp.now().year\n",
        "\n",
        "    # --- Match pattern 1 (years) ---\n",
        "    matches1 = re.findall(pattern1, text)\n",
        "    years += [float(m[0]) for m in matches1]\n",
        "\n",
        "    # --- Match pattern 2 (years) ---\n",
        "    matches2 = re.findall(pattern2, text)\n",
        "    years += [float(m[0]) for m in matches2]\n",
        "\n",
        "    # --- Match pattern 3 (date ranges like 2018 - 2022) ---\n",
        "    matches3 = re.findall(pattern3, text)\n",
        "    for start, end in matches3:\n",
        "        diff = int(end) - int(start)\n",
        "        if 0 < diff < 50:  # To avoid impossible ranges\n",
        "            years.append(diff)\n",
        "\n",
        "    # --- Match pattern 4 (since/from year, e.g., Since 2015) ---\n",
        "    matches4 = re.findall(pattern4, text)\n",
        "    for _, year in matches4:\n",
        "        diff = current_year - int(year)\n",
        "        if 0 < diff < 50:  # Reasonable year difference\n",
        "            years.append(diff)\n",
        "\n",
        "    # --- Match pattern 5 (experience of X years) ---\n",
        "    matches5 = re.findall(pattern5, text)\n",
        "    years += [float(m[0]) for m in matches5]\n",
        "\n",
        "    # --- Match pattern 6 (months converted to years) ---\n",
        "    matches6 = re.findall(pattern6, text)\n",
        "    months_as_years = [float(m[0]) / 12 for m in matches6 if float(m[0]) > 0]\n",
        "    years += months_as_years\n",
        "\n",
        "    # Return the highest valid value (or 0 if none found)\n",
        "    return round(max(years), 2) if years else 0\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def combine_scores(similarity_scores, experience_list, alpha=0.7, beta=0.3):\n",
        "    # Reshape to 2D arrays for scaler\n",
        "    similarity_array = np.array(similarity_scores).reshape(-1, 1)\n",
        "    experience_array = np.array(experience_list).reshape(-1, 1)\n",
        "\n",
        "    # Normalize both to [0, 1]\n",
        "    scaler = MinMaxScaler()\n",
        "    norm_similarity = scaler.fit_transform(similarity_array).flatten()\n",
        "    norm_experience = scaler.fit_transform(experience_array).flatten()\n",
        "\n",
        "    # Weighted sum\n",
        "    combined_score = alpha * norm_similarity + beta * norm_experience\n",
        "    return combined_score\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 5. Define Your Agent (After Functions)\n",
        "# ============================\n",
        "class ResumeScreeningAgent:\n",
        "    def __init__(self, job_description, candidate_experience):\n",
        "        self.job_description = job_description\n",
        "        self.job_vector = None\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.candidate_experience = candidate_experience\n",
        "\n",
        "    def perceive(self, resumes):\n",
        "        self.resume_vectors = self.vectorizer.fit_transform(resumes)\n",
        "        self.job_vector = self.vectorizer.transform([self.job_description])\n",
        "\n",
        "    def think(self):\n",
        "        self.similarity_scores = cosine_similarity(self.resume_vectors, self.job_vector).flatten()\n",
        "\n",
        "    def act(self):\n",
        "        # Use precomputed experience\n",
        "        experience_list = self.candidate_experience\n",
        "\n",
        "        # Combine scores\n",
        "        combined_score = combine_scores(self.similarity_scores, experience_list, alpha=0.7, beta=0.3)\n",
        "\n",
        "        # Rank the resumes based on combined score\n",
        "        ranked_results = pd.DataFrame({\n",
        "            'Candidate': candidate_names,\n",
        "            'Similarity Score': self.similarity_scores,\n",
        "            'Experience (yrs)': experience_list,\n",
        "            'Combined Score': combined_score\n",
        "        }).sort_values(by='Combined Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        print(\"Top Matching Candidates (Combined Ranking):\")\n",
        "        print(ranked_results.head(10))\n",
        "\n",
        "# ============================\n",
        "# 6. Loading Resumes\n",
        "# ============================\n",
        "resume_folder = \"/content/drive/My Drive/Resumes\"  # Your shared folder path\n",
        "\n",
        "candidate_names = []\n",
        "resumes = []\n",
        "candidate_experience = []\n",
        "\n",
        "for filename in os.listdir(resume_folder):\n",
        "    filepath = os.path.join(resume_folder, filename)\n",
        "    if filepath.endswith(\".pdf\") or filepath.endswith(\".docx\"):\n",
        "        raw_text = extract_resume_text(filepath)\n",
        "        cleaned_text = preprocess_text(raw_text)\n",
        "\n",
        "        resumes.append(cleaned_text)\n",
        "        candidate_names.append(filename)\n",
        "\n",
        "        years_of_exp = extract_years_of_experience(raw_text)\n",
        "        candidate_experience.append(years_of_exp)\n",
        "\n",
        "# ============================\n",
        "# 7. Run the Agent\n",
        "# ============================\n",
        "job_description_text = \"\"\"\n",
        "We are hiring a Data Analyst with strong knowledge of Python, SQL, and data visualization tools. Experience with machine learning and business analysis is a plus.\n",
        "\"\"\"\n",
        "\n",
        "agent = ResumeScreeningAgent(job_description_text, candidate_experience)\n",
        "agent.perceive(resumes)\n",
        "agent.think()\n",
        "agent.act()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnfgCah9Z9rq",
        "outputId": "e11a7b9a-c497-492c-d5d7-a5c9e9033d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.11/dist-packages (0.9)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Matching Candidates (Combined Ranking):\n",
            "                                     Candidate  Similarity Score  \\\n",
            "0                   rs_AYUSH - AYUSH AYUSH.pdf          0.353692   \n",
            "1  Tashi_Resume2 (2) - TASHI CHODEN BHUTIA.pdf          0.285162   \n",
            "2       Mansi Gambhir _ CV - Mansi Gambhir.pdf          0.234336   \n",
            "3        MokshSharma_Resume - Moksh Sharma.pdf          0.120972   \n",
            "4                   KomalGoel - Komal Goel.pdf          0.175822   \n",
            "5                              Profile (6).pdf          0.009343   \n",
            "6         Eesha_Singh_Resume - Eesha Singh.pdf          0.066711   \n",
            "7                rishika-1 - RISHIKA SINGH.pdf          0.147108   \n",
            "8                              Profile (3).pdf          0.042657   \n",
            "9                              Profile (2).pdf          0.104298   \n",
            "\n",
            "   Experience (yrs)  Combined Score  \n",
            "0              0.00        0.700000  \n",
            "1              0.00        0.564370  \n",
            "2              0.00        0.463779  \n",
            "3              3.50        0.389418  \n",
            "4              0.00        0.347972  \n",
            "5              7.00        0.318492  \n",
            "6              4.00        0.303458  \n",
            "7              0.00        0.291145  \n",
            "8              4.00        0.255852  \n",
            "9              0.17        0.213703  \n"
          ]
        }
      ]
    }
  ]
}